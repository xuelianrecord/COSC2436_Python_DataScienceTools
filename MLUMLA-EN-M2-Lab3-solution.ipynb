{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27cbdd6",
   "metadata": {},
   "source": [
    "<center><img src=\"images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# ML through Application\n",
    "## Module 2, Lab 3: Performing Basic Feature Engineering\n",
    "\n",
    "Feature engineering is an essential step in ML. Feature engineering involves using domain knowledge to transform raw data into features that an ML algorithm understands better. In this notebook, you will learn common techniques to transform numerical features, encode categorical features, and vectorize processed text features.\n",
    "\n",
    "You will learn how to do the following:\n",
    "\n",
    "- Begin data processing.\n",
    "- Know what feature scaling is and how to use it to improve your model.\n",
    "- Identify why and how to encode categoricals.\n",
    "- Perform basic text preprocessing.\n",
    "- Explain what text vectorization is and how to do it.\n",
    "\n",
    "----\n",
    "\n",
    "__Austin Animal Center Dataset__\n",
    "\n",
    "In this lab, you will work with historical pet adoption data in the [Austin Animal Center Shelter Intakes and Outcomes dataset](https://www.kaggle.com/datasets/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes?resource=download). The target field of the dataset (**Outcome Type**) is the outcome of adoption: 1 for adopted and 0 for not adopted. Multiple features are used in the dataset.\n",
    "\n",
    "Dataset schema:\n",
    "- __Pet ID:__ Unique ID of the pet\n",
    "- __Outcome Type:__ State of pet at the time of recording the outcome (0 = not placed, 1 = placed). This is the field to predict.\n",
    "- __Sex upon Outcome:__ Sex of pet at outcome\n",
    "- __Name:__ Name of pet \n",
    "- __Found Location:__ Found location of pet before it entered the shelter\n",
    "- __Intake Type:__ Circumstances that brought the pet to the shelter\n",
    "- __Intake Condition:__ Health condition of the pet when it entered the shelter\n",
    "- __Pet Type:__ Type of pet\n",
    "- __Sex upon Intake:__ Sex of pet when it entered the shelter\n",
    "- __Breed:__ Breed of pet \n",
    "- __Color:__ Color of pet \n",
    "- __Age upon Intake Days:__ Age (days) of pet when it entered the shelter\n",
    "- __Age upon Outcome Days:__ Age (days) of pet at outcome\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with two kinds of exercises throughout the notebook: activities and challenges. <br/>\n",
    "\n",
    "| <img style=\"float: center;\" src=\"images/activity.png\" alt=\"Activity\" width=\"125\"/>| <img style=\"float: center;\" src=\"images/challenge.png\" alt=\"Challenge\" width=\"125\"/>|\n",
    "| --- | --- |\n",
    "|<p style=\"text-align:center;\">No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p> |<p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e24374",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Data processing](#Data-processing)\n",
    "- [Feature scaling](#Feature-scaling)\n",
    "- [Encoding categoricals](#Encoding-categoricals)\n",
    "- [Text preprocessing](#Text-preprocessing)\n",
    "- [Text vectorization](#Text-vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9385add",
   "metadata": {},
   "source": [
    "---\n",
    "## Data processing\n",
    "\n",
    "First, process the dataset as you did in the previous labs in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ad35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install libraries\n",
    "!pip install -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554477d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa616c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the dataset into a DataFrame and look at the data\n",
    "df = pd.read_csv(\"data/review_dataset.csv\")\n",
    "\n",
    "print(\"The shape of the dataset is:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a4727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the first five rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657efc4",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, use commands that you saw in previous labs to print information about the dataset, including the number of rows, number of columns, and some simple statistics.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0fdce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "df.info()\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f829b9e",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, use the <code>columns</code> function on the DataFrame to print the names of the features to find the numerical subset.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9f413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0217f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify the numerical, categorical, and text features along with the target feature\n",
    "numerical_features = [\"Age upon Intake Days\", \"Age upon Outcome Days\"]\n",
    "\n",
    "categorical_features = [\n",
    "    \"Sex upon Outcome\",\n",
    "    \"Intake Type\",\n",
    "    \"Intake Condition\",\n",
    "    \"Pet Type\",\n",
    "    \"Sex upon Intake\",\n",
    "]\n",
    "\n",
    "text_features = [\"Name\", \"Found Location\", \"Breed\", \"Color\"]\n",
    "\n",
    "model_target = \"Outcome Type\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba6fae",
   "metadata": {},
   "source": [
    "To review the numerical features, use the `value_counts()` function to get a view of the feature values in respective bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566a131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print and plot statistics for the numerical features\n",
    "for c in numerical_features:\n",
    "    # Print the name of the feature\n",
    "    print(c)\n",
    "    # Print the value counts in 10 bins for each feature\n",
    "    print(df[c].value_counts(bins=10, sort=False))\n",
    "\n",
    "    # Plot bar charts based on value_counts (alternative plot method)\n",
    "    df[c].value_counts(bins=10, sort=False).plot(kind=\"bar\", alpha=0.75, rot=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72d973",
   "metadata": {},
   "source": [
    "If any outliers are identified as likely wrong values, dropping them could improve the numerical values histograms and overall model performance. One way to remove outliers is to remove any values in the upper 10 percent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in numerical_features:\n",
    "    # Drop values beyond 90% of max()\n",
    "    dropIndexes = df[df[c] > df[c].max() * 9 / 10].index\n",
    "    df.drop(dropIndexes, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172cb7da",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, print the distribution of numerical features into 10 bins.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\">Use the <code>value_counts()</code> function to print and plot the data for <i>both</i> numerical features.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f40abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### CODE HERE ###############\n",
    "\n",
    "for c in numerical_features:\n",
    "    print(c)\n",
    "    print(df[c].value_counts(bins=10, sort=False))\n",
    "    df[c].value_counts(bins=10, sort=False).plot(kind='bar',alpha=0.75, rot=90)\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55b363",
   "metadata": {},
   "source": [
    "### Drop rows with missing values\n",
    "\n",
    "The simplest way to handle missing data is to drop any row that is missing at least one value. Depending on your data, you might want to use imputation to replace values instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75580d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop all rows that are missing values\n",
    "df_missing_dropped = df.dropna()\n",
    "df_missing_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5db25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking if missing values were dropped: print the total number of rows for each feature that has missing values\n",
    "df_missing_dropped.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaa6493",
   "metadata": {},
   "source": [
    "---\n",
    "## Feature scaling\n",
    "\n",
    "Features being on different scales can affect ML algorithms. Feature scaling involves converting all numerical features to the same scale. \n",
    "\n",
    "**Particularly, scaling helps the most when multiple features have a range that are much different and don't overlap**. \n",
    "\n",
    "In this section, you will use sklearn's `MinMaxScaler` class, which transforms all the numerical features to values within the range of 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce43bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the numerical features before feature scaling\n",
    "df_missing_dropped[numerical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d570f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the MinMaxScaler class\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define the scaler\n",
    "feature_scaler = MinMaxScaler()\n",
    "scaled_features = feature_scaler.fit_transform(df_missing_dropped[numerical_features])\n",
    "# Scale the features\n",
    "df_scaled_numerical_features = pd.DataFrame(scaled_features, columns=numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a13b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the numerical features after feature scaling\n",
    "df_scaled_numerical_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915dd89f",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e06bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "from MLUMLA_EN_M2_Lab3_quiz_questions import *\n",
    "\n",
    "question_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc394263",
   "metadata": {},
   "source": [
    "---\n",
    "## Encoding categoricals\n",
    "\n",
    "A dataset might contain categorical features, which don't have a natural numerical representation. Most ML algorithms can't work with categorical inputs and require converting them to numerical representations. In this section, you will use sklearn's `OneHotEncoder` class to encode categorical features. \n",
    "\n",
    "__Note:__ The `handle_unknown` parameter tells the encoder to ignore (rather than throw an error for) any unique value that might show in the validation or test set but wasn't in the initial training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda2fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the categorical features before encoding\n",
    "df_missing_dropped[categorical_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985fe4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the shape of the categorical features in the DataFrame before encoding\n",
    "df_missing_dropped[categorical_features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c4728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the OneHotEncoder class\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define the encoder\n",
    "categorical_encoder = OneHotEncoder(\n",
    "    handle_unknown=\"ignore\"\n",
    ")  # handle_unknown tells the function to ignore any value that was not present in the initial training set\n",
    "encoded_categoricals = categorical_encoder.fit_transform(\n",
    "    df_missing_dropped[categorical_features]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef0a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the shape of the categorical features in the DataFrame after encoding\n",
    "print(\"The shape of the categorical feature set:\", encoded_categoricals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb990e1",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c920890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "question_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a787fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Text preprocessing\n",
    "\n",
    "The following are general techniques to clean text features:\n",
    "- Convert text to lowercase\n",
    "- Remove leading and trailing white space\n",
    "- Remove HTML tags and markups\n",
    "- Remove punctuation\n",
    "- Remove extra spaces and tabs\n",
    "- Remove numbers\n",
    "- Remove stop words\n",
    "- Stemming\n",
    "\n",
    "*Stop words* occur frequently in text and don't contribute much to the overall meaning of the sentence. This lab uses the following list of stop words for removal: a, an, the, this, that, is, it, to, and, in.\n",
    "\n",
    "*Stemming* is a rule-based system to convert a word into its root form. The process removes suffixes from words. This helps to enhance similarities (if any) between sentences. For example:\n",
    "- jumping, jumped > jump\n",
    "- cars -> car\n",
    "\n",
    "In this lab, you will use NLTK's SnowballStemmer for stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932969eb",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, define a list named <code>stop_words</code> that includes the stop words listed in the previous cell.\n",
    "    </p>\n",
    "    <br>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a36a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import re, string\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Define a list with the stop words: a, an, the, this, that, is, it, to, and, in\n",
    "############### CODE HERE ###############\n",
    "\n",
    "stop_words = [\"a\", \"an\", \"the\", \"this\", \"that\", \"is\", \"it\", \"to\", \"and\", \"in\",]\n",
    "\n",
    "############## END OF CODE ##############\n",
    "\n",
    "# Define the stemmer and language to use\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Define a function to remove white space, HTML, punctuation, and numbers\n",
    "def preProcessText(text):\n",
    "    # Lowercase text, and strip leading and trailing white space\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.compile(\"<.*?>\").sub(\"\", text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.compile(\"[%s]\" % re.escape(string.punctuation)).sub(\" \", text)\n",
    "\n",
    "    # Remove extra white space\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r\"[0-9]\", \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Define a function to remove stop words and stem the words\n",
    "def lexiconProcess(text, stop_words, stemmer):\n",
    "    filtered_sentence = []\n",
    "    words = text.split(\" \")\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(stemmer.stem(w))\n",
    "    text = \" \".join(filtered_sentence)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Define a function to clean a sentence\n",
    "def cleanSentence(text, stop_words, stemmer):\n",
    "    return lexiconProcess(preProcessText(text), stop_words, stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0206df",
   "metadata": {},
   "source": [
    "Now that the preprocessing functions have been defined, you will use the `cleanSentence` function on an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8c958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a variable to use for cleaning\n",
    "example_text = \"   This is a message to be cleaned. 31 It may involve some things like: <br>, ?, :, ''  adjacent spaces and tabs     .  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400df929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process and clean the example_text\n",
    "processed_text = cleanSentence(example_text, stop_words, stemmer)\n",
    "\n",
    "print(\"Original: \" + example_text + \"\\n\")\n",
    "print(\"Processed: \" + processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d03714",
   "metadata": {},
   "source": [
    "Notice that the processed sentence has words such as \"messag,\" \"involv,\" and \"adjac,\" which are not legitimate English words. This is how the stemmer works, which helps the algorithm to understand several words such as \"message,\" \"messaging,\" and \"messages\" as the same word, \"messag.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497bfe3f",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff467d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "question_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fc278",
   "metadata": {},
   "source": [
    "---\n",
    "## Text vectorization\n",
    "\n",
    "ML models cannot comprehend raw text data and require converting text data into numerical values. The technique for transforming text data into numerical representation is called *text vectorization*.\n",
    "\n",
    "You will use the *Bag of Words (BoW)* method for text vectorization. This method involves two steps:\n",
    "1. Create a vocabulary of words across the entire text feature.\n",
    "2. Measure the presence of the vocabulary words in each sample of the text feature.\n",
    "\n",
    "For an interactive example of the Bag of Words method, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475b761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mluvisuals import BagOfWords\n",
    "\n",
    "BagOfWords()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87091617",
   "metadata": {},
   "source": [
    "Now, you will use [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), which is the sklearn library's Bag of Words implementation, to perform text vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd14f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the text features before vectorization\n",
    "df_missing_dropped[text_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0cc502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the shape of the text features before text vectorization\n",
    "df_missing_dropped[text_features].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b46a63",
   "metadata": {},
   "source": [
    "You will examine one text feature, Found Location, and use the Bag of Words technique to vectorize it.\n",
    "\n",
    "__Note:__ The process is the same for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9aed71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the needed classes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Loop through each row of the \"Found Location\" feature in the DataFrame and\n",
    "# use the cleaning functions that you defined earlier in this lab\n",
    "cleaned_text_feature = [\n",
    "    cleanSentence(item, stop_words, stemmer)\n",
    "    for item in df_missing_dropped[\"Found Location\"]\n",
    "]\n",
    "\n",
    "# Define the count vectorizer\n",
    "countVectorizer = CountVectorizer(binary=True, max_features=100)\n",
    "\n",
    "# Vectorize the data\n",
    "text_feature_vectorized = countVectorizer.fit_transform(cleaned_text_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e89ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the shape of the DataFrame after vectorization\n",
    "text_feature_vectorized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883daddb",
   "metadata": {},
   "source": [
    "The shape of the DataFrame has changed. As expected, it has the same number of rows, but it now has 100 features. This relates directly to the `max_features` flag that was set when you defined the count vectorizer. You can set this number to control the number of features that your model uses to train. This can prevent rare words from having an impact on the model. You will need to adjust this parameter to meet your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ef915",
   "metadata": {},
   "source": [
    "The following cell prints the vocabulary created with words across the entire text feature by the vectorization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ada86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Vocabulary: \\n\", countVectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38aa7fd",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88686a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "question_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499729b5",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "This notebook helped you to understand and manipulate different types of features in a dataset so that you can create the best ML model. Understanding and preparing data is one of the most important steps to build a successful ML model.\n",
    "\n",
    "## Next lab\n",
    "\n",
    "In the next lab, you will build a logistic regression model to predict the Outcome Type field of the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
