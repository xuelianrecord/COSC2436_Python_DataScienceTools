{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# ML through Application\n",
    "## Module 1, Lab 3: Getting Started with AutoGluon\n",
    "\n",
    "This notebook covers how to create a model to solve an ML problem by using [AutoGluon](https://auto.gluon.ai/stable/index.html#).\n",
    "\n",
    "You will learn how to do the following:\n",
    "\n",
    "- Import the AutoGluon library.\n",
    "- Import data to a Pandas DataFrame.\n",
    "- Train a model by using AutoGluon.\n",
    "\n",
    "---\n",
    "\n",
    "You will explore a dataset that contains information about books. The goal is to predict book prices by using features about the books.\n",
    "\n",
    "__Business problem:__ Books from a large database with several features cannot be listed for sale because one critical piece of information is missing: the price. \n",
    "\n",
    "__ML problem description:__ Predict book prices by using book features, such as genre, release data, ratings, and number of reviews.\n",
    "\n",
    "This is a regression task (the training dataset has a book price column to use for labels).\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with two kinds of exercises throughout the notebook: activities and challenges. <br/>\n",
    "\n",
    "| <img style=\"float: center;\" src=\"images/activity.png\" alt=\"Activity\" width=\"125\"/>| <img style=\"float: center;\" src=\"images/challenge.png\" alt=\"Challenge\" width=\"125\"/>|\n",
    "| --- | --- |\n",
    "|<p style=\"text-align:center;\">No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p> |<p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "- [Importing AutoGluon](#Importing-AutoGluon)\n",
    "- [Getting the data](#Getting-the-data)\n",
    "- [Model training with AutoGluon](#Model-training-with-AutoGluon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importing AutoGluon\n",
    "\n",
    "Install and load the libraries that are needed to work with the tabular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Use pip to install libraries\n",
    "!pip install -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the libraries that are needed for the notebook\n",
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "# Import utility functions and challenge questions\n",
    "from MLUMLA_EN_M1_Lab3_quiz_questions import *\n",
    "\n",
    "# Import the newly installed AutoGluon code library\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting the data\n",
    "\n",
    "Now get the data for the business problem. \n",
    "\n",
    "__Note:__ You will use the [Amazon Product Reviews](https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews) dataset. For more information about this dataset, see the following resources:\n",
    "\n",
    "- Ruining He and Julian McAuley. \"Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering.\" Proceedings of the 25th International Conference on World Wide Web, Geneva, Switzerland, April 2016. https://doi.org/10.1145/2872427.2883037.\n",
    "\n",
    "- Julian McAuley, Christopher Targett, Qinfeng Shi, Anton van den Hengel. \"Image-Based Recommendations on Styles and Substitutes.\" Proceedings of the 38th International Association for Computing Machinery (ACM) Special Interest Group on Information Retrieval (SIGIR) Conference on Research and Development in Information Retrieval, Santiago, Chile, August 2015. https://doi.org/10.1145/2766462.2767755."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the training and test data, and then show the first few rows of the training dataset, run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = TabularDataset(data=\"data/train.csv\")\n",
    "df_test = TabularDataset(data=\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>Price</th>\n",
       "      <th>asin</th>\n",
       "      <th>details</th>\n",
       "      <th>descriptionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>Books\" /&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>Joan M. Lexau</td>\n",
       "      <td>1,683,587 in Books (</td>\n",
       "      <td>['0590457292']</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.48</td>\n",
       "      <td>B001D4OHQA</td>\n",
       "      <td>{'Publisher:': 'Scholastic (1974)', 'Language:...</td>\n",
       "      <td>Staining on cover, minimal wear and creasing. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Books', 'Education &amp; Teaching', 'Schools &amp; T...</td>\n",
       "      <td>The Core Knowledge Sequence Content and Skill ...</td>\n",
       "      <td>['0325008957', '1138188492', '1890517208', '14...</td>\n",
       "      <td>Core Knowledge Foundation</td>\n",
       "      <td>974,014 in Books (</td>\n",
       "      <td>['0385316402', '1890517208', '1933486058', '19...</td>\n",
       "      <td>Books</td>\n",
       "      <td>21.40</td>\n",
       "      <td>B0071QRBFS</td>\n",
       "      <td>{'Paperback:': '400 pages', 'Publisher:': 'Cor...</td>\n",
       "      <td>A double volume with two &amp;quot;front covers.&amp;q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>Stranger In The Woods</td>\n",
       "      <td>[]</td>\n",
       "      <td>Leah Fried</td>\n",
       "      <td>17,588,750 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>17.00</td>\n",
       "      <td>965906523X</td>\n",
       "      <td>{'Hardcover:': '202 pages', 'Publisher:': 'Fel...</td>\n",
       "      <td>Stranger in the woods is a dramatic tale of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>Hansel and Gretel :  A Fairy Opera, Vocal Score</td>\n",
       "      <td>[]</td>\n",
       "      <td>Adelheid ; Bache, Constance ; Humperdinck, E. ...</td>\n",
       "      <td>3,680,123 in Books (</td>\n",
       "      <td>['0793506603']</td>\n",
       "      <td>Books</td>\n",
       "      <td>10.95</td>\n",
       "      <td>B0011ZV86I</td>\n",
       "      <td>{'Publisher:': 'G. Schirmer, Inc. (1957)', 'AS...</td>\n",
       "      <td>Complete vocal score, words and music.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Books', 'History', 'Asia']</td>\n",
       "      <td>Genghis Khan - Conqueror Of The World</td>\n",
       "      <td>[]</td>\n",
       "      <td>Leo De Hartog</td>\n",
       "      <td>5,083,249 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>3.50</td>\n",
       "      <td>B001LIQC7A</td>\n",
       "      <td>{'Hardcover:': '230 pages', 'Publisher:': 'Bar...</td>\n",
       "      <td>a great biography of Ghengis Khan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            category  \\\n",
       "0                                                 []   \n",
       "1  ['Books', 'Education & Teaching', 'Schools & T...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                       ['Books', 'History', 'Asia']   \n",
       "\n",
       "                                               title  \\\n",
       "0                                          Books\" />   \n",
       "1  The Core Knowledge Sequence Content and Skill ...   \n",
       "2                              Stranger In The Woods   \n",
       "3    Hansel and Gretel :  A Fairy Opera, Vocal Score   \n",
       "4              Genghis Khan - Conqueror Of The World   \n",
       "\n",
       "                                            also_buy  \\\n",
       "0                                                 []   \n",
       "1  ['0325008957', '1138188492', '1890517208', '14...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                               brand                   rank  \\\n",
       "0                                      Joan M. Lexau   1,683,587 in Books (   \n",
       "1                          Core Knowledge Foundation     974,014 in Books (   \n",
       "2                                         Leah Fried  17,588,750 in Books (   \n",
       "3  Adelheid ; Bache, Constance ; Humperdinck, E. ...   3,680,123 in Books (   \n",
       "4                                      Leo De Hartog   5,083,249 in Books (   \n",
       "\n",
       "                                           also_view main_cat  Price  \\\n",
       "0                                     ['0590457292']    Books   5.48   \n",
       "1  ['0385316402', '1890517208', '1933486058', '19...    Books  21.40   \n",
       "2                                                 []    Books  17.00   \n",
       "3                                     ['0793506603']    Books  10.95   \n",
       "4                                                 []    Books   3.50   \n",
       "\n",
       "         asin                                            details  \\\n",
       "0  B001D4OHQA  {'Publisher:': 'Scholastic (1974)', 'Language:...   \n",
       "1  B0071QRBFS  {'Paperback:': '400 pages', 'Publisher:': 'Cor...   \n",
       "2  965906523X  {'Hardcover:': '202 pages', 'Publisher:': 'Fel...   \n",
       "3  B0011ZV86I  {'Publisher:': 'G. Schirmer, Inc. (1957)', 'AS...   \n",
       "4  B001LIQC7A  {'Hardcover:': '230 pages', 'Publisher:': 'Bar...   \n",
       "\n",
       "                                   descriptionstring  \n",
       "0  Staining on cover, minimal wear and creasing. ...  \n",
       "1  A double volume with two &quot;front covers.&q...  \n",
       "2  Stranger in the woods is a dramatic tale of co...  \n",
       "3             Complete vocal score, words and music.  \n",
       "4                  a great biography of Ghengis Khan  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>var Quiz=function(){\"use strict\";var M=document.createElement(\"style\");M.textContent=`.quiz-wrapper.svelte-fk6ar3{padding:1rem}.footer.svelte-fk6ar3{display:flex;align-items:center}h2.svelte-fk6ar3{font-size:1.5rem;margin-bottom:2rem;color:#232f3e}p.svelte-fk6ar3{font-size:16px}.options.svelte-fk6ar3{display:grid;grid-template-columns:repeat(2,50%);grid-template-rows:repeat(2,1fr);width:100%;margin:auto;justify-content:center}.mlu-quizquestion-option-button.svelte-fk6ar3{padding:1rem;margin:.5rem}.submit-button.svelte-fk6ar3{padding:1rem;margin:.5rem;width:90px;color:#fff;background-color:coral}.active.svelte-fk6ar3{background-color:#232f3e;color:#fff}.correct-answer.svelte-fk6ar3{background-color:green}.incorrect-answer.svelte-fk6ar3{background-color:red;text-decoration:line-through}.available.svelte-fk6ar3{pointer-events:none;opacity:.6}\n",
       "`,document.head.appendChild(M);function I(){}function P(e){return e()}function W(){return Object.create(null)}function O(e){e.forEach(P)}function X(e){return typeof e==\"function\"}function Z(e,t){return e!=e?t==t:e!==t||e&&typeof e==\"object\"||typeof e==\"function\"}function x(e){return Object.keys(e).length===0}function m(e,t){e.appendChild(t)}function j(e,t,n){e.insertBefore(t,n||null)}function z(e){e.parentNode&&e.parentNode.removeChild(e)}function ee(e,t){for(let n=0;n<e.length;n+=1)e[n]&&e[n].d(t)}function k(e){return document.createElement(e)}function A(e){return document.createTextNode(e)}function S(){return A(\" \")}function te(){return A(\"\")}function Y(e,t,n,r){return e.addEventListener(t,n,r),()=>e.removeEventListener(t,n,r)}function v(e,t,n){n==null?e.removeAttribute(t):e.getAttribute(t)!==n&&e.setAttribute(t,n)}function ne(e){return Array.from(e.childNodes)}function T(e,t){t=\"\"+t,e.wholeText!==t&&(e.data=t)}function p(e,t,n){e.classList[n?\"add\":\"remove\"](t)}let L;function N(e){L=e}const $=[],D=[],Q=[],F=[],re=Promise.resolve();let B=!1;function oe(){B||(B=!0,re.then(H))}function R(e){Q.push(e)}const G=new Set;let E=0;function H(){if(E!==0)return;const e=L;do{try{for(;E<$.length;){const t=$[E];E++,N(t),le(t.$$)}}catch(t){throw $.length=0,E=0,t}for(N(null),$.length=0,E=0;D.length;)D.pop()();for(let t=0;t<Q.length;t+=1){const n=Q[t];G.has(n)||(G.add(n),n())}Q.length=0}while($.length);for(;F.length;)F.pop()();B=!1,G.clear(),N(e)}function le(e){if(e.fragment!==null){e.update(),O(e.before_update);const t=e.dirty;e.dirty=[-1],e.fragment&&e.fragment.p(e.ctx,t),e.after_update.forEach(R)}}const ie=new Set;function se(e,t){e&&e.i&&(ie.delete(e),e.i(t))}function ce(e,t,n,r){const{fragment:l,after_update:i}=e.$$;l&&l.m(t,n),r||R(()=>{const s=e.$$.on_mount.map(P).filter(X);e.$$.on_destroy?e.$$.on_destroy.push(...s):O(s),e.$$.on_mount=[]}),i.forEach(R)}function fe(e,t){const n=e.$$;n.fragment!==null&&(O(n.on_destroy),n.fragment&&n.fragment.d(t),n.on_destroy=n.fragment=null,n.ctx=[])}function ue(e,t){e.$$.dirty[0]===-1&&($.push(e),oe(),e.$$.dirty.fill(0)),e.$$.dirty[t/31|0]|=1<<t%31}function ae(e,t,n,r,l,i,s,g=[-1]){const c=L;N(e);const o=e.$$={fragment:null,ctx:[],props:i,update:I,not_equal:l,bound:W(),on_mount:[],on_destroy:[],on_disconnect:[],before_update:[],after_update:[],context:new Map(t.context||(c?c.$$.context:[])),callbacks:W(),dirty:g,skip_bound:!1,root:t.target||c.$$.root};s&&s(o.root);let b=!1;if(o.ctx=n?n(e,t.props||{},(a,q,...y)=>{const h=y.length?y[0]:q;return o.ctx&&l(o.ctx[a],o.ctx[a]=h)&&(!o.skip_bound&&o.bound[a]&&o.bound[a](h),b&&ue(e,a)),q}):[],o.update(),b=!0,O(o.before_update),o.fragment=r?r(o.ctx):!1,t.target){if(t.hydrate){const a=ne(t.target);o.fragment&&o.fragment.l(a),a.forEach(z)}else o.fragment&&o.fragment.c();t.intro&&se(e.$$.fragment),ce(e,t.target,t.anchor,t.customElement),H()}N(c)}class de{$destroy(){fe(this,1),this.$destroy=I}$on(t,n){if(!X(n))return I;const r=this.$$.callbacks[t]||(this.$$.callbacks[t]=[]);return r.push(n),()=>{const l=r.indexOf(n);l!==-1&&r.splice(l,1)}}$set(t){this.$$set&&!x(t)&&(this.$$.skip_bound=!0,this.$$set(t),this.$$.skip_bound=!1)}}const be=\"\";function J(e,t,n){const r=e.slice();return r[11]=t[n],r[13]=n,r}function K(e){let t,n=e[11]+\"\",r,l,i,s;function g(){return e[9](e[13])}return{c(){t=k(\"button\"),r=A(n),l=S(),v(t,\"class\",\"mlu-quizquestion-option-button button svelte-fk6ar3\"),p(t,\"active\",e[5]===e[13]),p(t,\"correct-answer\",e[1]&&e[5]===e[13]&&e[2]==e[0].correctIndex),p(t,\"incorrect-answer\",e[1]&&e[5]===e[13]&&e[2]!=e[0].correctIndex),p(t,\"available\",e[4]&&e[1])},m(c,o){j(c,t,o),m(t,r),m(t,l),i||(s=Y(t,\"click\",g),i=!0)},p(c,o){e=c,o&1&&n!==(n=e[11]+\"\")&&T(r,n),o&32&&p(t,\"active\",e[5]===e[13]),o&39&&p(t,\"correct-answer\",e[1]&&e[5]===e[13]&&e[2]==e[0].correctIndex),o&39&&p(t,\"incorrect-answer\",e[1]&&e[5]===e[13]&&e[2]!=e[0].correctIndex),o&18&&p(t,\"available\",e[4]&&e[1])},d(c){c&&z(t),i=!1,s()}}}function U(e){let t;function n(i,s){return i[3]==!0?he:_e}let r=n(e),l=r(e);return{c(){l.c(),t=te()},m(i,s){l.m(i,s),j(i,t,s)},p(i,s){r!==(r=n(i))&&(l.d(1),l=r(i),l&&(l.c(),l.m(t.parentNode,t)))},d(i){l.d(i),i&&z(t)}}}function _e(e){let t;return{c(){t=k(\"p\"),t.textContent=\"This is not the correct answer. Try again!\",v(t,\"class\",\"svelte-fk6ar3\")},m(n,r){j(n,t,r)},d(n){n&&z(t)}}}function he(e){let t;return{c(){t=k(\"p\"),t.textContent=\"Good! You got the correct answer.\",v(t,\"class\",\"svelte-fk6ar3\")},m(n,r){j(n,t,r)},d(n){n&&z(t)}}}function me(e){let t,n,r=e[0].question+\"\",l,i,s,g,c,o,b=e[1]?\"Retry\":\"Submit\",a,q,y,h,C=e[0].options,d=[];for(let f=0;f<C.length;f+=1)d[f]=K(J(e,C,f));let _=e[1]&&U(e);return{c(){t=k(\"div\"),n=k(\"h2\"),l=A(r),i=S(),s=k(\"div\");for(let f=0;f<d.length;f+=1)d[f].c();g=S(),c=k(\"div\"),o=k(\"button\"),a=A(b),q=S(),_&&_.c(),v(n,\"class\",\"svelte-fk6ar3\"),v(s,\"class\",\"options svelte-fk6ar3\"),v(o,\"class\",\"submit-button svelte-fk6ar3\"),p(o,\"available\",!e[4]),v(c,\"class\",\"footer svelte-fk6ar3\"),v(t,\"class\",\"quiz-wrapper svelte-fk6ar3\")},m(f,w){j(f,t,w),m(t,n),m(n,l),m(t,i),m(t,s);for(let u=0;u<d.length;u+=1)d[u].m(s,null);m(t,g),m(t,c),m(c,o),m(o,a),m(c,q),_&&_.m(c,null),y||(h=Y(o,\"click\",e[10]),y=!0)},p(f,[w]){if(w&1&&r!==(r=f[0].question+\"\")&&T(l,r),w&311){C=f[0].options;let u;for(u=0;u<C.length;u+=1){const V=J(f,C,u);d[u]?d[u].p(V,w):(d[u]=K(V),d[u].c(),d[u].m(s,null))}for(;u<d.length;u+=1)d[u].d(1);d.length=C.length}w&2&&b!==(b=f[1]?\"Retry\":\"Submit\")&&T(a,b),w&16&&p(o,\"available\",!f[4]),f[1]?_?_.p(f,w):(_=U(f),_.c(),_.m(c,null)):_&&(_.d(1),_=null)},i:I,o:I,d(f){f&&z(t),ee(d,f),_&&_.d(),y=!1,h()}}}function pe(e,t,n){let{question:r={question:\"Who didn't attend this meeting?\",options:[\"Xin\",\"Anand\",\"Brent\"],correctIndex:2}}=t,l=!1,i=-1,s=\"no\",g=!1,c;function o(){n(4,g=!1),n(1,l=!1),n(2,i=-1),n(5,c=-1),n(3,s=\"no\")}function b(){n(1,l=!0),n(3,s=i==r.correctIndex)}function a(h){n(4,g=!0),n(2,i=h),n(5,c=h)}const q=h=>a(h),y=()=>l?o():b();return e.$$set=h=>{\"question\"in h&&n(0,r=h.question)},[r,l,i,s,g,c,o,b,a,q,y]}class ge extends de{constructor(t){super(),ae(this,t,pe,me,Z,{question:0})}}return ge}();\n",
       "</script>\n",
       "        \n",
       "        <div id=\"Quiz-2c81975e\"></div>\n",
       "        <script>\n",
       "        (() => {\n",
       "            var data = {\n",
       "\"question\": {\n",
       "\"question\": \"What value does previewing the data provide?\",\n",
       "\"options\": [\n",
       "\"It allows you to see the columns and the first rows of data in the dataset.\",\n",
       "\"It tells you which columns you need to clean to make a good model.\",\n",
       "\"It shows the importance of each column to the dataset.\"\n",
       "],\n",
       "\"correctIndex\": 0\n",
       "}\n",
       "};\n",
       "            window.Quiz_data = data;\n",
       "            var Quiz_inst = new Quiz({\n",
       "                \"target\": document.getElementById(\"Quiz-2c81975e\"),\n",
       "                \"props\": data\n",
       "            });\n",
       "        })();\n",
       "        </script>\n",
       "        \n",
       "        "
      ],
      "text/plain": [
       "<MLUMLA_EN_M1_Lab3_quiz_questions.Quiz at 0x7f07d478eda0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "question_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model training with AutoGluon\n",
    "\n",
    "You can use AutoGluon to train a model by using a single line of code. You need to provide the dataset and tell AutoGluon which column from the dataset you are trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">To prepare the datasets, run the following cell.<br/>\n",
    "        This step is not required for AutoGluon to work, but it will reduce the time to train your first model.<br/>\n",
    "The code randomly selects 1,000 rows from the dataset and splits them into training and validation datasets.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>Price</th>\n",
       "      <th>asin</th>\n",
       "      <th>details</th>\n",
       "      <th>descriptionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>[]</td>\n",
       "      <td>Every Last One (Audiobook CD)</td>\n",
       "      <td>['1491546336', '1600244041', '1524754668', '14...</td>\n",
       "      <td>Visit Amazon's -Anna Quindlen- Page</td>\n",
       "      <td>6,392,575 in Books (</td>\n",
       "      <td>['0812985907', '0525509879', '0812976185', '08...</td>\n",
       "      <td>Books</td>\n",
       "      <td>23.84</td>\n",
       "      <td>B003SFS8F8</td>\n",
       "      <td>{'Publisher:': 'Unabridged edition; Unabridged...</td>\n",
       "      <td>The latest novel from Pulitzer Prize-winner An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>[]</td>\n",
       "      <td>Books\" /&gt;</td>\n",
       "      <td>['0441810764', '0312863551', '0441094996', '04...</td>\n",
       "      <td>Robert A Heinlein</td>\n",
       "      <td>4,893,400 in Books (</td>\n",
       "      <td>['0441810764', '0312863551', '0671577808', '04...</td>\n",
       "      <td>Books</td>\n",
       "      <td>6.74</td>\n",
       "      <td>B001R2GZA4</td>\n",
       "      <td>{'Publisher:': 'SIGNET BOOKS (1900)', 'ASIN:':...</td>\n",
       "      <td>Classic science fiction novel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>['Books', 'Reference']</td>\n",
       "      <td>Review Notes and Study Guide to  Conrad's Vict...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ken Sobol</td>\n",
       "      <td>2,286,014 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>8.07</td>\n",
       "      <td>B000QCDE5A</td>\n",
       "      <td>{'Paperback:': '142 pages', 'Publisher:': 'Mon...</td>\n",
       "      <td>A CRITICAL GUIDE BY MONARCH NOTES.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4572</th>\n",
       "      <td>[]</td>\n",
       "      <td>Simon's Cat va al veterinario</td>\n",
       "      <td>[]</td>\n",
       "      <td>Simon Tofield</td>\n",
       "      <td>7,769,270 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>15.18</td>\n",
       "      <td>8416261865</td>\n",
       "      <td>{'Publisher:': 'Duomo Ediciones (October 1, 20...</td>\n",
       "      <td>Brand New. Ship worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>['Books', 'Arts &amp;amp; Photography', 'Decorativ...</td>\n",
       "      <td>Taisho Kimono: Speaking of Past and Present</td>\n",
       "      <td>['4756246354']</td>\n",
       "      <td>Visit Amazon's Jan Dees Page</td>\n",
       "      <td>2,053,979 in Books (</td>\n",
       "      <td>[]</td>\n",
       "      <td>Books</td>\n",
       "      <td>51.75</td>\n",
       "      <td>8857200116</td>\n",
       "      <td>{'Hardcover:': '292 pages', 'Publisher:': 'Ski...</td>\n",
       "      <td>A unique collection of 130 kimonos for women, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               category  \\\n",
       "398                                                  []   \n",
       "3833                                                 []   \n",
       "4836                             ['Books', 'Reference']   \n",
       "4572                                                 []   \n",
       "636   ['Books', 'Arts &amp; Photography', 'Decorativ...   \n",
       "\n",
       "                                                  title  \\\n",
       "398                       Every Last One (Audiobook CD)   \n",
       "3833                                          Books\" />   \n",
       "4836  Review Notes and Study Guide to  Conrad's Vict...   \n",
       "4572                      Simon's Cat va al veterinario   \n",
       "636         Taisho Kimono: Speaking of Past and Present   \n",
       "\n",
       "                                               also_buy  \\\n",
       "398   ['1491546336', '1600244041', '1524754668', '14...   \n",
       "3833  ['0441810764', '0312863551', '0441094996', '04...   \n",
       "4836                                                 []   \n",
       "4572                                                 []   \n",
       "636                                      ['4756246354']   \n",
       "\n",
       "                                    brand                  rank  \\\n",
       "398   Visit Amazon's -Anna Quindlen- Page  6,392,575 in Books (   \n",
       "3833                    Robert A Heinlein  4,893,400 in Books (   \n",
       "4836                            Ken Sobol  2,286,014 in Books (   \n",
       "4572                        Simon Tofield  7,769,270 in Books (   \n",
       "636          Visit Amazon's Jan Dees Page  2,053,979 in Books (   \n",
       "\n",
       "                                              also_view main_cat  Price  \\\n",
       "398   ['0812985907', '0525509879', '0812976185', '08...    Books  23.84   \n",
       "3833  ['0441810764', '0312863551', '0671577808', '04...    Books   6.74   \n",
       "4836                                                 []    Books   8.07   \n",
       "4572                                                 []    Books  15.18   \n",
       "636                                                  []    Books  51.75   \n",
       "\n",
       "            asin                                            details  \\\n",
       "398   B003SFS8F8  {'Publisher:': 'Unabridged edition; Unabridged...   \n",
       "3833  B001R2GZA4  {'Publisher:': 'SIGNET BOOKS (1900)', 'ASIN:':...   \n",
       "4836  B000QCDE5A  {'Paperback:': '142 pages', 'Publisher:': 'Mon...   \n",
       "4572  8416261865  {'Publisher:': 'Duomo Ediciones (October 1, 20...   \n",
       "636   8857200116  {'Hardcover:': '292 pages', 'Publisher:': 'Ski...   \n",
       "\n",
       "                                      descriptionstring  \n",
       "398   The latest novel from Pulitzer Prize-winner An...  \n",
       "3833                     Classic science fiction novel.  \n",
       "4836                 A CRITICAL GUIDE BY MONARCH NOTES.  \n",
       "4572                          Brand New. Ship worldwide  \n",
       "636   A unique collection of 130 kimonos for women, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling 1,000\n",
    "# Try setting the subsample_size to a much larger value to see what happens during training\n",
    "subsample_size = 1000  # Sample a subset of the data for faster demo\n",
    "df_train_smaller = df_train.sample(n=subsample_size, random_state=0)\n",
    "\n",
    "# Print the first few rows\n",
    "df_train_smaller.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>var Quiz=function(){\"use strict\";var M=document.createElement(\"style\");M.textContent=`.quiz-wrapper.svelte-fk6ar3{padding:1rem}.footer.svelte-fk6ar3{display:flex;align-items:center}h2.svelte-fk6ar3{font-size:1.5rem;margin-bottom:2rem;color:#232f3e}p.svelte-fk6ar3{font-size:16px}.options.svelte-fk6ar3{display:grid;grid-template-columns:repeat(2,50%);grid-template-rows:repeat(2,1fr);width:100%;margin:auto;justify-content:center}.mlu-quizquestion-option-button.svelte-fk6ar3{padding:1rem;margin:.5rem}.submit-button.svelte-fk6ar3{padding:1rem;margin:.5rem;width:90px;color:#fff;background-color:coral}.active.svelte-fk6ar3{background-color:#232f3e;color:#fff}.correct-answer.svelte-fk6ar3{background-color:green}.incorrect-answer.svelte-fk6ar3{background-color:red;text-decoration:line-through}.available.svelte-fk6ar3{pointer-events:none;opacity:.6}\n",
       "`,document.head.appendChild(M);function I(){}function P(e){return e()}function W(){return Object.create(null)}function O(e){e.forEach(P)}function X(e){return typeof e==\"function\"}function Z(e,t){return e!=e?t==t:e!==t||e&&typeof e==\"object\"||typeof e==\"function\"}function x(e){return Object.keys(e).length===0}function m(e,t){e.appendChild(t)}function j(e,t,n){e.insertBefore(t,n||null)}function z(e){e.parentNode&&e.parentNode.removeChild(e)}function ee(e,t){for(let n=0;n<e.length;n+=1)e[n]&&e[n].d(t)}function k(e){return document.createElement(e)}function A(e){return document.createTextNode(e)}function S(){return A(\" \")}function te(){return A(\"\")}function Y(e,t,n,r){return e.addEventListener(t,n,r),()=>e.removeEventListener(t,n,r)}function v(e,t,n){n==null?e.removeAttribute(t):e.getAttribute(t)!==n&&e.setAttribute(t,n)}function ne(e){return Array.from(e.childNodes)}function T(e,t){t=\"\"+t,e.wholeText!==t&&(e.data=t)}function p(e,t,n){e.classList[n?\"add\":\"remove\"](t)}let L;function N(e){L=e}const $=[],D=[],Q=[],F=[],re=Promise.resolve();let B=!1;function oe(){B||(B=!0,re.then(H))}function R(e){Q.push(e)}const G=new Set;let E=0;function H(){if(E!==0)return;const e=L;do{try{for(;E<$.length;){const t=$[E];E++,N(t),le(t.$$)}}catch(t){throw $.length=0,E=0,t}for(N(null),$.length=0,E=0;D.length;)D.pop()();for(let t=0;t<Q.length;t+=1){const n=Q[t];G.has(n)||(G.add(n),n())}Q.length=0}while($.length);for(;F.length;)F.pop()();B=!1,G.clear(),N(e)}function le(e){if(e.fragment!==null){e.update(),O(e.before_update);const t=e.dirty;e.dirty=[-1],e.fragment&&e.fragment.p(e.ctx,t),e.after_update.forEach(R)}}const ie=new Set;function se(e,t){e&&e.i&&(ie.delete(e),e.i(t))}function ce(e,t,n,r){const{fragment:l,after_update:i}=e.$$;l&&l.m(t,n),r||R(()=>{const s=e.$$.on_mount.map(P).filter(X);e.$$.on_destroy?e.$$.on_destroy.push(...s):O(s),e.$$.on_mount=[]}),i.forEach(R)}function fe(e,t){const n=e.$$;n.fragment!==null&&(O(n.on_destroy),n.fragment&&n.fragment.d(t),n.on_destroy=n.fragment=null,n.ctx=[])}function ue(e,t){e.$$.dirty[0]===-1&&($.push(e),oe(),e.$$.dirty.fill(0)),e.$$.dirty[t/31|0]|=1<<t%31}function ae(e,t,n,r,l,i,s,g=[-1]){const c=L;N(e);const o=e.$$={fragment:null,ctx:[],props:i,update:I,not_equal:l,bound:W(),on_mount:[],on_destroy:[],on_disconnect:[],before_update:[],after_update:[],context:new Map(t.context||(c?c.$$.context:[])),callbacks:W(),dirty:g,skip_bound:!1,root:t.target||c.$$.root};s&&s(o.root);let b=!1;if(o.ctx=n?n(e,t.props||{},(a,q,...y)=>{const h=y.length?y[0]:q;return o.ctx&&l(o.ctx[a],o.ctx[a]=h)&&(!o.skip_bound&&o.bound[a]&&o.bound[a](h),b&&ue(e,a)),q}):[],o.update(),b=!0,O(o.before_update),o.fragment=r?r(o.ctx):!1,t.target){if(t.hydrate){const a=ne(t.target);o.fragment&&o.fragment.l(a),a.forEach(z)}else o.fragment&&o.fragment.c();t.intro&&se(e.$$.fragment),ce(e,t.target,t.anchor,t.customElement),H()}N(c)}class de{$destroy(){fe(this,1),this.$destroy=I}$on(t,n){if(!X(n))return I;const r=this.$$.callbacks[t]||(this.$$.callbacks[t]=[]);return r.push(n),()=>{const l=r.indexOf(n);l!==-1&&r.splice(l,1)}}$set(t){this.$$set&&!x(t)&&(this.$$.skip_bound=!0,this.$$set(t),this.$$.skip_bound=!1)}}const be=\"\";function J(e,t,n){const r=e.slice();return r[11]=t[n],r[13]=n,r}function K(e){let t,n=e[11]+\"\",r,l,i,s;function g(){return e[9](e[13])}return{c(){t=k(\"button\"),r=A(n),l=S(),v(t,\"class\",\"mlu-quizquestion-option-button button svelte-fk6ar3\"),p(t,\"active\",e[5]===e[13]),p(t,\"correct-answer\",e[1]&&e[5]===e[13]&&e[2]==e[0].correctIndex),p(t,\"incorrect-answer\",e[1]&&e[5]===e[13]&&e[2]!=e[0].correctIndex),p(t,\"available\",e[4]&&e[1])},m(c,o){j(c,t,o),m(t,r),m(t,l),i||(s=Y(t,\"click\",g),i=!0)},p(c,o){e=c,o&1&&n!==(n=e[11]+\"\")&&T(r,n),o&32&&p(t,\"active\",e[5]===e[13]),o&39&&p(t,\"correct-answer\",e[1]&&e[5]===e[13]&&e[2]==e[0].correctIndex),o&39&&p(t,\"incorrect-answer\",e[1]&&e[5]===e[13]&&e[2]!=e[0].correctIndex),o&18&&p(t,\"available\",e[4]&&e[1])},d(c){c&&z(t),i=!1,s()}}}function U(e){let t;function n(i,s){return i[3]==!0?he:_e}let r=n(e),l=r(e);return{c(){l.c(),t=te()},m(i,s){l.m(i,s),j(i,t,s)},p(i,s){r!==(r=n(i))&&(l.d(1),l=r(i),l&&(l.c(),l.m(t.parentNode,t)))},d(i){l.d(i),i&&z(t)}}}function _e(e){let t;return{c(){t=k(\"p\"),t.textContent=\"This is not the correct answer. Try again!\",v(t,\"class\",\"svelte-fk6ar3\")},m(n,r){j(n,t,r)},d(n){n&&z(t)}}}function he(e){let t;return{c(){t=k(\"p\"),t.textContent=\"Good! You got the correct answer.\",v(t,\"class\",\"svelte-fk6ar3\")},m(n,r){j(n,t,r)},d(n){n&&z(t)}}}function me(e){let t,n,r=e[0].question+\"\",l,i,s,g,c,o,b=e[1]?\"Retry\":\"Submit\",a,q,y,h,C=e[0].options,d=[];for(let f=0;f<C.length;f+=1)d[f]=K(J(e,C,f));let _=e[1]&&U(e);return{c(){t=k(\"div\"),n=k(\"h2\"),l=A(r),i=S(),s=k(\"div\");for(let f=0;f<d.length;f+=1)d[f].c();g=S(),c=k(\"div\"),o=k(\"button\"),a=A(b),q=S(),_&&_.c(),v(n,\"class\",\"svelte-fk6ar3\"),v(s,\"class\",\"options svelte-fk6ar3\"),v(o,\"class\",\"submit-button svelte-fk6ar3\"),p(o,\"available\",!e[4]),v(c,\"class\",\"footer svelte-fk6ar3\"),v(t,\"class\",\"quiz-wrapper svelte-fk6ar3\")},m(f,w){j(f,t,w),m(t,n),m(n,l),m(t,i),m(t,s);for(let u=0;u<d.length;u+=1)d[u].m(s,null);m(t,g),m(t,c),m(c,o),m(o,a),m(c,q),_&&_.m(c,null),y||(h=Y(o,\"click\",e[10]),y=!0)},p(f,[w]){if(w&1&&r!==(r=f[0].question+\"\")&&T(l,r),w&311){C=f[0].options;let u;for(u=0;u<C.length;u+=1){const V=J(f,C,u);d[u]?d[u].p(V,w):(d[u]=K(V),d[u].c(),d[u].m(s,null))}for(;u<d.length;u+=1)d[u].d(1);d.length=C.length}w&2&&b!==(b=f[1]?\"Retry\":\"Submit\")&&T(a,b),w&16&&p(o,\"available\",!f[4]),f[1]?_?_.p(f,w):(_=U(f),_.c(),_.m(c,null)):_&&(_.d(1),_=null)},i:I,o:I,d(f){f&&z(t),ee(d,f),_&&_.d(),y=!1,h()}}}function pe(e,t,n){let{question:r={question:\"Who didn't attend this meeting?\",options:[\"Xin\",\"Anand\",\"Brent\"],correctIndex:2}}=t,l=!1,i=-1,s=\"no\",g=!1,c;function o(){n(4,g=!1),n(1,l=!1),n(2,i=-1),n(5,c=-1),n(3,s=\"no\")}function b(){n(1,l=!0),n(3,s=i==r.correctIndex)}function a(h){n(4,g=!0),n(2,i=h),n(5,c=h)}const q=h=>a(h),y=()=>l?o():b();return e.$$set=h=>{\"question\"in h&&n(0,r=h.question)},[r,l,i,s,g,c,o,b,a,q,y]}class ge extends de{constructor(t){super(),ae(this,t,pe,me,Z,{question:0})}}return ge}();\n",
       "</script>\n",
       "        \n",
       "        <div id=\"Quiz-6a75457\"></div>\n",
       "        <script>\n",
       "        (() => {\n",
       "            var data = {\n",
       "\"question\": {\n",
       "\"question\": \"Why would you train your first model with a smaller sample size?\",\n",
       "\"options\": [\n",
       "\"A model trained from small sample size will make better predictions than one trained on the full dataset.\",\n",
       "\"So you can delete bad datapoints before training.\",\n",
       "\"To speed up model training.\"\n",
       "],\n",
       "\"correctIndex\": 2\n",
       "}\n",
       "};\n",
       "            window.Quiz_data = data;\n",
       "            var Quiz_inst = new Quiz({\n",
       "                \"target\": document.getElementById(\"Quiz-6a75457\"),\n",
       "                \"props\": data\n",
       "            });\n",
       "        })();\n",
       "        </script>\n",
       "        \n",
       "        "
      ],
      "text/plain": [
       "<MLUMLA_EN_M1_Lab3_quiz_questions.Quiz at 0x7f07d478fe20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "question_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model with a small sample\n",
    "\n",
    "AutoGluon uses certain defaults. For example, AutoGluon uses `root_mean_squared_error` as an evaluation metric for regression problems. For more information, see [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) in the sklearn documentation.\n",
    "\n",
    "__Note:__ Training on this smaller dataset will take approximately 3–4 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">Use `TabularPredictor` to train the first version of the model along with the smaller 1000 sample training dataset so the model trains faster.<br>\n",
    "</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230928_033751/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230928_033751/\"\n",
      "AutoGluon Version:  0.8.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Mon Apr 24 23:34:06 UTC 2023\n",
      "Disk Space Avail:   19.81 GB / 20.96 GB (94.5%)\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 10\n",
      "Label Column: Price\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2326.87, 0.0, 39.77738, 123.6481)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14447.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['category', 'title', 'also_buy', 'brand', 'rank', 'also_view', 'details', 'descriptionstring']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 336\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['asin']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['asin']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', [])       : 1 | ['main_cat']\n",
      "\t\t('object', ['text']) : 8 | ['category', 'title', 'also_buy', 'brand', 'rank', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   1 | ['main_cat']\n",
      "\t\t('category', ['text_as_category'])  :   8 | ['category', 'title', 'also_buy', 'brand', 'rank', ...]\n",
      "\t\t('int', ['binned', 'text_special']) : 111 | ['category.char_count', 'category.word_count', 'category.capital_ratio', 'category.lower_ratio', 'category.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 321 | ['__nlp__.10', '__nlp__.10 inches', '__nlp__.10 inches shipping', '__nlp__.100', '__nlp__.11', ...]\n",
      "\t10.2s = Fit runtime\n",
      "\t9 features in original data used to generate 441 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 10.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\t-14434.1496\t = Validation score   (-mean_squared_error)\n",
      "\t15.48s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-14056.59\t = Validation score   (-mean_squared_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-3911.5212\t = Validation score   (-mean_squared_error)\n",
      "\t4.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-3922.4337\t = Validation score   (-mean_squared_error)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-10183.4639\t = Validation score   (-mean_squared_error)\n",
      "\t9.55s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-3903.7043\t = Validation score   (-mean_squared_error)\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-5877.9003\t = Validation score   (-mean_squared_error)\n",
      "\t4.91s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "Matplotlib is building the font cache; this may take a moment.\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-4302.1333\t = Validation score   (-mean_squared_error)\n",
      "\t13.22s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-4498.6691\t = Validation score   (-mean_squared_error)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-3884.0907\t = Validation score   (-mean_squared_error)\n",
      "\t7.31s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-3944.1853\t = Validation score   (-mean_squared_error)\n",
      "\t2.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-3767.6277\t = Validation score   (-mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 78.3s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230928_033751/\")\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "\n",
    "smaller_predictor = TabularPredictor(label=\"Price\", eval_metric = 'mean_squared_error').fit(train_data=df_train_smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the training output\n",
    "AutoGluon outputs a lot of information about what happens during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\"> \n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <p style=\"text-align:center; margin:auto;\"><img src=\"images/challenge.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">After the training finishes, examine the output and answer the following questions based on the output.</p>\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the shape of the training dataset?\n",
    "2. What type of ML problem (such as classification or regression) does AutoGluon infer? (**Hint:** Remember, you didn't mention the problem type. You only provided the label column.)\n",
    "3. What does AutoGluon suggest in case it inferred the wrong problem type?\n",
    "4. What kind of data preprocessing and feature engineering did AutoGluon perform?\n",
    "5. What are the basic statistics about the label in the print statements from AutoGluon?\n",
    "6. How many extra features were generated in addition to the originals in the dataset? What was the runtime for that?\n",
    "7. Which evaluation metric was used?\n",
    "8. What does AutoGluon suggest in case it inferred the wrong metric?\n",
    "9. What is the ratio between the training and validation dataset? (**Hint:** Look for `val` or `validation`.)\n",
    "10. Where did AutoGluon save the predictor?\n",
    "11. Which folder were the models saved in?\n",
    "12. What file format are the models in? (**Note:** Look at the file name suffix. You don't need to open the file.)\n",
    "\n",
    "Try to answer these questions before you check the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List your answers here:\n",
    "1. 1000 Rows and 10 Columns (1000, 10)\n",
    "\n",
    "2. AutoGluon infers your prediction problem is: 'regression'\n",
    "\n",
    "3. It suggests to manually specify the problem_type parameter during predictor init (['binary', 'multiclass', 'regression'])\n",
    "\n",
    "4. AutoGluon performed various data preprocessing and feature engineering tasks, including: Data type inference for each feature; Fitting feature generators (AsTypeFeatureGenerator, FillNaFeatureGenerator, CategoryFeatureGenerator, TextSpecialFeatureGenerator, TextNgramFeatureGenerator, etc.); BinnedFeatureGenerator, CountVectorizer, and removed unused features.\n",
    "\n",
    "5. Label info (max, min, mean, stddev): (2326.87, 0.0, 39.77738, 123.6481)\n",
    "Maximum value: 2326.87\n",
    "Minimum value: 0.0\n",
    "Mean: 39.77738\n",
    "Standard deviation: 123.6481\n",
    "\n",
    "6. 441 features in addition to the original 9 features in the dataset. The runtime for this feature generation was 10.3 seconds.\n",
    "\n",
    "7. AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_error'\n",
    "\n",
    "8. It mentions that one can change the evaluation metric by specifying the 'eval_metric' parameter of Predictor()\n",
    "\n",
    "9. Train Rows: 800, Val Rows: 200\n",
    "\n",
    "10. AutoGluon saved the predictor in the following directory: \"AutogluonModels/ag-20230928_033751/\"\n",
    "\n",
    "11. Models were saved in the \"AutogluonModels/ag-20230928_033751/\" folder\n",
    "\n",
    "12. The models are saved in .pkl format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "The purpose of this notebook was to explore a dataset of information about books and to use AutoGluon to build a basic model to predict book prices based on book features.\n",
    "\n",
    "## Next lab\n",
    "In the next lab, you will learn how to use AutoGluon features to refine your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
