{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae9dc1e",
   "metadata": {},
   "source": [
    "<center><img src=\"images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# ML through Application\n",
    "## Module 2, Lab 5: Using Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is an important process to select optimal sets of parameters and settings for ML models. In this notebook, you will gain experience with two main types of hyperparameter tuning: grid search and randomized search. In this notebook, you will use a decision tree model, but hyperparameter tuning can be applied to any model type.\n",
    "\n",
    "You will learn the following:\n",
    "\n",
    "- How features are used with a decision tree model\n",
    "- What grid search is and how to use it\n",
    "- What randomized search is and how to use it\n",
    "\n",
    "----\n",
    "\n",
    "__Austin Animal Center Dataset__\n",
    "\n",
    "In this lab, you will work with historical pet adoption data in the [Austin Animal Center Shelter Intakes and Outcomes dataset](https://www.kaggle.com/datasets/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes?resource=download). The target field of the dataset (**Outcome Type**) is the outcome of adoption: 1 for adopted and 0 for not adopted. Multiple features are used in the dataset.\n",
    "\n",
    "Dataset schema:\n",
    "- __Pet ID:__ Unique ID of the pet\n",
    "- __Outcome Type:__ State of pet at the time of recording the outcome (0 = not placed, 1 = placed). This is the field to predict.\n",
    "- __Sex upon Outcome:__ Sex of pet at outcome\n",
    "- __Name:__ Name of pet \n",
    "- __Found Location:__ Found location of pet before it entered the shelter\n",
    "- __Intake Type:__ Circumstances that brought the pet to the shelter\n",
    "- __Intake Condition:__ Health condition of the pet when it entered the shelter\n",
    "- __Pet Type:__ Type of pet\n",
    "- __Sex upon Intake:__ Sex of pet when it entered the shelter\n",
    "- __Breed:__ Breed of pet \n",
    "- __Color:__ Color of pet \n",
    "- __Age upon Intake Days:__ Age (days) of pet when it entered the shelter\n",
    "- __Age upon Outcome Days:__ Age (days) of pet at outcome\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with two kinds of exercises throughout the notebook: activities and challenges. <br/>\n",
    "\n",
    "| <img style=\"float: center;\" src=\"images/activity.png\" alt=\"Activity\" width=\"125\"/>| <img style=\"float: center;\" src=\"images/challenge.png\" alt=\"Challenge\" width=\"125\"/>|\n",
    "| --- | --- |\n",
    "|<p style=\"text-align:center;\">No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p> |<p style=\"text-align:center;\">Challenges are where you can practice your coding skills.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c9551",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Features and the decision tree model](#Features-and-the-decision-tree-model)\n",
    "- [Grid search](#Grid-search)\n",
    "- [Randomized search](#Randomized-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9118de",
   "metadata": {},
   "source": [
    "---\n",
    "## Features and the decision tree model\n",
    "\n",
    "In this section, you will process the categorical and text features of the dataset, and use them to fit a simple decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dabdf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install libraries\n",
    "!pip install -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22564cc7",
   "metadata": {},
   "source": [
    "First, load the required libraries, read the dataset into a DataFrame, and look at that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb38d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "df = pd.read_csv(\"data/review_dataset.csv\")\n",
    "\n",
    "print(\"The shape of the dataset is:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0f3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba6ee6",
   "metadata": {},
   "source": [
    "The model will use the numerical, categorical, and text features. To use them, you need to create lists that contain the feature names:\n",
    "\n",
    "- __Numerical features:__ Age upon Intake Days, Age upon Outcome Days\n",
    "- __Categorical features:__ Sex upon Outcome, Intake Type, Intake Condition, Pet Type, Sex upon Intake, Breed, Color\n",
    "- __Text features:__ Found Location\n",
    "- __Target:__ Outcome Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eed2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Numerical features\n",
    "numerical_features = [\"Age upon Intake Days\", \"Age upon Outcome Days\"]\n",
    "\n",
    "# Drop the ID features: RescuerID and PetID\n",
    "categorical_features = [\n",
    "    \"Sex upon Outcome\",\n",
    "    \"Intake Type\",\n",
    "    \"Intake Condition\",\n",
    "    \"Pet Type\",\n",
    "    \"Sex upon Intake\",\n",
    "    \"Breed\",\n",
    "    \"Color\",\n",
    "]\n",
    "\n",
    "# Based on exploratory data analysis (EDA), select the text features\n",
    "text_features = [\"Found Location\"]\n",
    "\n",
    "model_features = numerical_features + categorical_features + text_features\n",
    "model_target = \"Outcome Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaaf438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41010110",
   "metadata": {},
   "source": [
    "__Note:__\n",
    "* Some categories might be boolean types, False and True. Booleans will raise errors when you try to encode the categoricals with sklearn encoders because none of them accept boolean types. If you use the Pandas `get_dummies` function to one-hot encode the categoricals, you don't need to convert the Booleans. However, [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) is more difficult to use with sklearn's [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) functions.\n",
    "\n",
    "* One way to handle Booleans is to convert them to strings by using a mask and a map changing only the Booleans. Another way is to convert them to strings by changing the type of all categoricals to `str`. This will also affect the nansâ€”basically performing imputation of the nans with a `nans` string placeholder value.\n",
    "\n",
    "* Applying the type conversion to both categoricals and text features handles the nans in the text fields as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e387c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[categorical_features + text_features] = df[\n",
    "    categorical_features + text_features\n",
    "].astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c07782",
   "metadata": {},
   "source": [
    "Now, check for missing values for the categorical features and text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efddf301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df[categorical_features + text_features].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c71b8",
   "metadata": {},
   "source": [
    "Convertion from categoricals into useful numerical features should be done **after splitting the dataset for training and testing**.\n",
    "\n",
    "If you encode the categoricals on the whole dataset before you split it into train/validation/test sets you will introduce bias into the training. The introduction of bias happens because the encoded categories will now contain information about the samples that will be in your validation and/or test sets.\n",
    "This is commonly called `data leakage` and it is a problem because the purpose of your validation and test sets is to apply your trained model to data that it has not seen before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c6219",
   "metadata": {},
   "source": [
    "### Cleaning the text fields\n",
    "\n",
    "__Note:__ The cleaning stage can take a few minutes, depending on how much text needs to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e0429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare cleaning functions\n",
    "\n",
    "stop_words = [\"a\", \"an\", \"the\", \"this\", \"that\", \"is\", \"it\", \"to\", \"and\"]\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def preProcessText(text):\n",
    "    # Lowercase text, and strip leading and trailing white space\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.compile(\"<.*?>\").sub(\"\", text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.compile(\"[%s]\" % re.escape(string.punctuation)).sub(\" \", text)\n",
    "\n",
    "    # Remove extra white space\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def lexiconProcess(text, stop_words, stemmer):\n",
    "    filtered_sentence = []\n",
    "    words = text.split(\" \")\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(stemmer.stem(w))\n",
    "    text = \" \".join(filtered_sentence)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def cleanSentence(text, stop_words, stemmer):\n",
    "    return lexiconProcess(preProcessText(text), stop_words, stemmer)\n",
    "\n",
    "\n",
    "# Clean the text features\n",
    "for c in text_features:\n",
    "    print(\"Text cleaning: \", c)\n",
    "    df[c] = [cleanSentence(item, stop_words, stemmer) for item in df[c].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a56ca",
   "metadata": {},
   "source": [
    "The cleaned text feature is ready to be vectorized after the dataset split. \n",
    "\n",
    "__Note:__ More exploratory data analysis (EDA) might reveal other important hidden attributes or relationships of the model features that are being considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e6a5f",
   "metadata": {},
   "source": [
    "### Create training and test datasets\n",
    "\n",
    "As part of data preparation, the dataset is split into training and test subsets by using sklearn's [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function.\n",
    "\n",
    "For this notebook, you will use 90 percent of the data for the training set and 10 percent for the test set. Determine the best split based on the size of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b63c3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    df, test_size=0.1, shuffle=True, random_state=23\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf7534",
   "metadata": {},
   "source": [
    "### Process the data with a pipeline and ColumnTransformer\n",
    "\n",
    "In this section, you will build separate pipelines to handle the numerical, categorical, and text features. Then, you will combine them into a composite pipeline along with an estimator. To do this, you will use a [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "* __Numerical processor:__ A MinMaxScaler can be used for numerical features; however, you don't need to scale features when using decision trees. You will use one here to see how to use more data transforms. If different processing is desired for different numerical features, you should build different pipelines as described for the text features pipeline. See the `numerical_processor` in the following code cell.\n",
    "   \n",
    "* __Categorical processor:__ Impute with a placeholder value (this won't have an effect because you already encoded the 'nan' values), and encode with sklearn's OneHotEncoder. If computing memory is an issue, it is a good idea to check the number of unique values for the categoricals to get an estimate of how many dummy features one-hot encoding will create. Note the `handle_unknown` parameter, which tells the encoder to ignore (rather than throw an error for) any unique value that might show in the validation or test set that was not present in the initial training set. See the `categorical_processor` in the following code cell.\n",
    "  \n",
    "* __Text processor:__ With memory usage in mind, build two more pipelines, one for each of the text features, and try different vocabulary sizes.\n",
    "\n",
    "Finally, the selective preparations of the dataset features are then put together into a collective ColumnTransformer, which is used in a pipeline along with an estimator. This ensures that the transforms are performed automatically in all situations. This includes on the raw data when fitting the model, when making predictions, when evaluating the model on a validation dataset through cross-validation, or when making predictions on a test dataset in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d31bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### COLUMN_TRANSFORMER ###\n",
    "##########################\n",
    "\n",
    "# Preprocess the numerical features\n",
    "numerical_processor = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"num_scaler\",\n",
    "            MinMaxScaler(),\n",
    "        )  # Shown in case it is needed. Not a must with decision trees.\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess the categorical features\n",
    "# handle_unknown tells it to ignore (rather than throw an error for) any value\n",
    "# that was not present in the initial training set.\n",
    "categorical_processor = Pipeline(\n",
    "    [(\"cat_encoder\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "# Preprocess the text feature\n",
    "# This text processor uses max_features=150\n",
    "text_processor_0 = Pipeline(\n",
    "    [(\"text_vect_0\", CountVectorizer(binary=True, max_features=150))]\n",
    ")\n",
    "\n",
    "# Combine all data preprocessors (add more if you choose to define more)\n",
    "# For each processor/step, specify: a name, the actual process, and the features to be processed\n",
    "data_preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical_pre\", numerical_processor, numerical_features),\n",
    "        (\"categorical_pre\", categorical_processor, categorical_features),\n",
    "        (\"text_pre_0\", text_processor_0, text_features[0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "### PIPELINE ###\n",
    "################\n",
    "\n",
    "# Pipeline with all desired data transformers, along with an estimator\n",
    "# Later, you can set/reach the parameters by using the names issued - for hyperparameter tuning, for example\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"data_preprocessing\", data_preprocessor),\n",
    "        (\"dt\", DecisionTreeClassifier(max_depth=5)),\n",
    "    ]\n",
    ")  # The initial value is chosen as max_depth=5\n",
    "\n",
    "# Visualize the pipeline\n",
    "# This will be helpful especially when building more complex pipelines,\n",
    "# stringing together multiple preprocessing steps\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da84faf",
   "metadata": {},
   "source": [
    "Now that your pipeline is ready, you can train and print the training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4de69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get training data to train the pipeline\n",
    "X_train = train_data[model_features]\n",
    "y_train = train_data[model_target]\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Use the fitted pipeline to make predictions on the training dataset\n",
    "train_predictions = pipeline.predict(X_train)\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Accuracy (training):\", accuracy_score(y_train, train_predictions))\n",
    "\n",
    "# Get testing data to test the pipeline\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Use the fitted pipeline to make predictions on the testing dataset\n",
    "test_predictions = pipeline.predict(X_test)\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(\"Accuracy (test):\", accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85edca",
   "metadata": {},
   "source": [
    "---\n",
    "## Grid search\n",
    "\n",
    "When you created the pipelines, you used a few hyperparameters, such `max_depth=5` for the decision tree and `max_features=150` for vectorizers, without exploring other alternatives. Now that you have seen the results of the fixed values, you will use grid search to automatically look for good combinations of multiple hyperparameters.\n",
    "\n",
    "You will use sklearn's [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to look for hyperparameter combinations to improve the accuracy on the testing set (and reduce the generalization gap). `GridSearchCV` does the cross-validation train-validation split internally. The data transformers inside the pipeline context will force the correct behavior of learning data transformations on the training set. The same way, it will apply the transformations to the validation set when cross-validating as well as on the test set later when running test predictions.\n",
    "\n",
    "__Note:__ Setting pipeline step names gives easy access to hyperparameters for hyperparameter tuning while cross-validating. Parameters of the estimators in the pipeline can be accessed using the `estimator__parameter` syntax. Make sure you use double underscores to connect estimator and parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c5ce39",
   "metadata": {},
   "source": [
    "The next code block might take some time to complete because there are 9 candidate (3x3) hyperparameters. With 5-fold cross-validation, this will result in a total of 45 fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c60bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### PIPELINE GRID_SEARCH ###\n",
    "############################\n",
    "\n",
    "# Parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    \"dt__max_depth\": [100, 200, 300],\n",
    "    \"dt__min_samples_leaf\": [5, 10, 15],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,  # Base model\n",
    "    param_grid,  # Parameters to try\n",
    "    cv=5,  # Apply 5-fold cross validation\n",
    "    verbose=1,  # Print summary\n",
    "    n_jobs=-1,  # Use all available processors\n",
    ")\n",
    "\n",
    "# Fit the GridSearch to the training data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0a307",
   "metadata": {},
   "source": [
    "Now that the grid search has completed, you can look at what it found to be the best hyperparameters and the corresponding highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee6b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91487188",
   "metadata": {},
   "source": [
    "Next, you can pick the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb265fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the best model out of GridSearchCV\n",
    "classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model to the training data once more\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc27d5f",
   "metadata": {},
   "source": [
    "Finally, you can look at the test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ced84d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get testing data to test the classifier\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Use the fitted model to make predictions on the testing dataset\n",
    "# Testing data going through the pipeline is first imputed\n",
    "# (with means from the training set), scaled (with the min/max from the training data),\n",
    "# and finally used to make predictions.\n",
    "test_predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"Model performance on the test set:\")\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838b62e",
   "metadata": {},
   "source": [
    "From the results, you can see that this model has done better when compared to the testing set. If you continue to explore different hyperparameters, you might be able to do event better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705cbd18",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc4c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "from MLUMLA_EN_M2_Lab5_quiz_questions import *\n",
    "\n",
    "question_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198fdf4",
   "metadata": {},
   "source": [
    "---\n",
    "## Randomized search\n",
    "\n",
    "An alternative way to find the optimal hyperparameters is through randomized search. This method chooses a fixed number (given by parameter `n_iter`) of random combinations of hyperparameter values and only tries each. This method can also sample from distributions (sampling with replacement is used), if at least one parameter is given as a distribution.\n",
    "\n",
    "In the following cell, the `max_depth` and `min_samples_leaf` hyperparameters are searched. \n",
    "\n",
    "Sklearn's randomized search method has a default 10 number of iterations, which means 10 combinations to try. Totaling 50 fits with 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05b67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### PIPELINE RANDOMIZED_SEARCH ###\n",
    "############################\n",
    "from scipy.stats import randint\n",
    "# Parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    \"dt__max_depth\": [100, 200, 300],\n",
    "    'dt__min_samples_leaf' :randint(15, 35)\n",
    "    #\"dt__min_samples_leaf\": [5, 10, 15]\n",
    "}\n",
    "\n",
    "randomized_search = RandomizedSearchCV(\n",
    "    pipeline,  # Base model\n",
    "    param_grid,  # Parameters to try\n",
    "    cv=5,  # Apply 5-fold cross validation\n",
    "    verbose=1,  # Print summary\n",
    "    n_jobs=-1,  # Use all available processors\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearch to the training data\n",
    "randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc4904",
   "metadata": {},
   "source": [
    "When the randomized search completes, look at what it found to be the best hyperparameters and the corresponding highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36a499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(randomized_search.best_params_)\n",
    "print(randomized_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a16ad",
   "metadata": {},
   "source": [
    "Next, you can pick the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39517a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the best model out of GridSearchCV\n",
    "classifier = randomized_search.best_estimator_\n",
    "\n",
    "# Fit the best model to the training data once more\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd2569",
   "metadata": {},
   "source": [
    "Finally, you can look at the test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bcf416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get testing data to test the classifier\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Use the fitted model to make predictions on the testing dataset\n",
    "# Testing data going through the pipeline is first imputed\n",
    "# (with means from the training set), scaled (with the min/max from the training data),\n",
    "# and finally used to make predictions\n",
    "test_predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"Model performance on the test set:\")\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce63a87",
   "metadata": {},
   "source": [
    "The randomized search might not give better results (because it is random, the outcome will vary). You can adjust the ranges to try and improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0b188",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/challenge.png\" alt=\"Challenge\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">Add another parameter to the search.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\">In the following code cell, add <code>'dt__min_samples_split': randint(2, 50)</code> to the grid, and run the randomized search again.</p><br>\n",
    "    <p style=\" text-align: center; margin: auto;\">After the training completes, check the test score as you did previously.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cdb42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameter grid for randomized search\n",
    "\n",
    "############### CODE HERE ###############\n",
    "\n",
    "param_grid={'dt__max_depth': [100, 200, 300],#, 50, 75, 100, 125, 150, 200, 250],\n",
    "            'dt__min_samples_leaf' :randint(15, 35),  # Picks an integer randomly between 15 and 35\n",
    "            'dt__min_samples_split' :randint(2, 50)\n",
    "           }\n",
    "\n",
    "randomized_search = RandomizedSearchCV(pipeline, # Base model\n",
    "                                       param_grid, # Parameters to try\n",
    "                                       cv = 5, # Apply 5-fold cross validation\n",
    "                                       verbose = 1, # Print summary\n",
    "                                       n_jobs = -1 # Use all available processors\n",
    "                                      )\n",
    "############## END OF CODE ##############\n",
    "\n",
    "# Fit the RandomizedSearch to the training data\n",
    "randomized_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d763eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(randomized_search.best_params_)\n",
    "print(randomized_search.best_score_)\n",
    "\n",
    "# Get the best model out of GridSearchCV\n",
    "classifier = randomized_search.best_estimator_\n",
    "\n",
    "# Fit the best model to the training data once more\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9a8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get testing data to test the classifier\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Use the fitted model to make predictions on the testing dataset\n",
    "# Testing data going through the pipeline is first imputed\n",
    "# (with means from the training set), scaled (with the min/max from the training data),\n",
    "# and finally used to make predictions\n",
    "test_predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"Model performance on the test set:\")\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0d027",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>It's time to check your knowledge!</i></h3>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To load the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c2c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "\n",
    "question_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dcdbf",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "This notebook showed you how to tune hyperparameters to improve your model.\n",
    "\n",
    "## Next lab\n",
    "\n",
    "In the next lab, you will gain experience with ensemble methods to create a strong model by combining the predictions of multiple weak models (also known as weak learners or base estimators) that are built with a given dataset and a given learning algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
