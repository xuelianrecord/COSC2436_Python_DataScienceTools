{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center><br/>\n",
    "\n",
    "# ML through Application \n",
    "## Module 3, Lab 2, Notebook 1: Exploring Data for Bias\n",
    "\n",
    "This notebook shows you how to look for bias in data by quantifying and visualizing correlations (scatterplots and correlation matrices) and by generating descriptive statistics (histograms). You will also see how to use the class imbalance ($CI_{norm}$) and difference in proportion of positive labels ($DPL$) metrics. When you build an ML model, you want to try as many metrics as possible to look for bias.\n",
    "\n",
    "You will learn how to do the following:\n",
    "- Create scatterplots.\n",
    "- Create correlation matrices.\n",
    "- Calculate class imbalance (CI) and difference in proportion of labels (DPL).\n",
    "\n",
    "__Dataset:__ \n",
    "You will use [Folktables](https://github.com/zykls/folktables) to download a dataset for this lab. Folktables provides an API to download data from the American Community Survey (ACS) Public Use Microdata Sample (PUMS) files, which the U.S. Census Bureau manages. The data itself is governed by the terms of use that are provided by the Census Bureau. For more information, see the [Terms of Service](https://www.census.gov/data/developers/about/terms-of-service.html). \n",
    "\n",
    "You will filter the ACS PUMS data sample to include only individuals who are above the age of 16, reported usual working hours of at least 1 hour per week in the past year, and have an income of at least \\\\$100. \n",
    "The threshold of \\\\$50,000 was chosen so that this dataset can serve as a comparable replacement to the [UCI Adult dataset](https://archive.ics.uci.edu/ml/datasets/adult), but the income threshold can be changed easily to define new prediction tasks. Historically, the [UCI Adult dataset](https://archive.ics.uci.edu/ml/datasets/adult) served as the basis for the development and comparison of many algorithmic fairness interventions but has limited documentation, outdated feature encodings, and only contains a binary target label which can lead to misrepresentations for certain subpopulations. In order to compare your results with scientific findings that utilize the UCI Adult dataset, and to have greater control and flexibility in setting up the problem, you will utilize the ACS PUMS data with the filters and thresholds described above.\n",
    "\n",
    "__ML problem:__ \n",
    "The goal is to predict whether an individual's income is above \\\\$50,000. \n",
    "This is a binary prediction task that can enable organizations and businesses to target their marketing efforts more effectively. Alternatively, governments could leverage these predictions to design better social welfare programs and allocate resources efficiently. Keep these kinds of problems in mind, when working through the notebook.\n",
    "\n",
    "Reference: Dua, D. and Graff, C. (2019). UCI Machine Learning Repository. http://archive.ics.uci.edu/ml. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with activities throughout the notebook: <br/>\n",
    "\n",
    "|<img style=\"float: center;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>| \n",
    "| --- | \n",
    "|<p style=\"text-align:center;\"> No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Loading data](#Loading-data)\n",
    "- [Basic data processing](#Basic-data-processing)\n",
    "- [Bar plots and histograms](#Bar-plots-and-histograms)\n",
    "- [Scatterplots](#Scatterplots)\n",
    "- [Correlation matrices](#Correlation-matrices)\n",
    "- [DPL and CI](#DPL-and-CI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading in the dataset, make sure to install and import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pip to install libraries\n",
    "!pip install --no-deps -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries needed for the notebook\n",
    "\n",
    "# Reshaping/basic libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set default seaborn color scheme\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# Operational libraries\n",
    "from MLUMLA_EN_M3_Lab2_quiz_questions import *\n",
    "\n",
    "# Fairness libraries\n",
    "from folktables.acs import *\n",
    "from folktables.folktables import *\n",
    "from folktables.load_acs import *\n",
    "\n",
    "# Jupyter(lab) libraries\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading data\n",
    "\n",
    "To read in the dataset, you will use [Folktables](https://github.com/zykls/folktables), as described earlier in this lab. Folktables contains predefined prediction tasks but also allows the user to specify the problem type.\n",
    "\n",
    "The U.S. Census Bureau dataset distinguishes between households and individuals. To obtain data on individuals, you will use `ACSDataSource` with `survey=\"person\"`. The feature names for the data follow the same distinction, and use *P* for person and *H* for household. For example, AGEP refers to the age of an individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_features = [\n",
    "    \"AGEP\",  # age individual\n",
    "    \"COW\",  # class of worker\n",
    "    \"SCHL\",  # educational attainment\n",
    "    \"MAR\",  # marital status\n",
    "    \"OCCP\",  # occupation\n",
    "    \"POBP\",  # place of birth\n",
    "    \"RELP\",  # relationship\n",
    "    \"WKHP\",  # hours worked per week past 12 months\n",
    "    \"SEX\",  # sex\n",
    "    \"RAC1P\",  # recorded detailed race code\n",
    "    \"PWGTP\",  # persons weight\n",
    "    \"GCL\",  # grandparents living with grandchildren\n",
    "    \"SCH\",  # school enrollment\n",
    "]\n",
    "\n",
    "# Define the prediction problem and features\n",
    "ACSIncome = folktables.BasicProblem(\n",
    "    features=income_features,\n",
    "    target=\"PINCP\",  # total persons income\n",
    "    target_transform=lambda x: x > 50000,\n",
    "    group=\"RAC1P\",\n",
    "    preprocess=adult_filter,  # applies the following conditions; ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    postprocess=lambda x: x,  # applies post processing, e.g. fill all NAs\n",
    ")\n",
    "\n",
    "# Initialize year, duration (\"1-Year\" or \"5-Year\") and granularity (household or person)\n",
    "data_source = ACSDataSource(survey_year=\"2018\", horizon=\"1-Year\", survey=\"person\")\n",
    "# Specify region (here: California) and load data\n",
    "ca_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "# Apply transformation as per problem statement above\n",
    "ca_features, ca_labels, ca_group = ACSIncome.df_to_numpy(ca_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Basic data processing\n",
    "\n",
    "First, you want to go through basic steps of exploratory data analysis (EDA) to perform initial data investigations to discover patterns, spot anomalies, and look for insights to inform later ML modeling choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "df = pd.DataFrame(\n",
    "    np.concatenate((ca_features, ca_labels.reshape(-1, 1)), axis=1),\n",
    "    columns=income_features + [\">50k\"],\n",
    ")\n",
    "\n",
    "# Print the first five rows\n",
    "# NaN means missing data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many rows and columns are in the DataFrame\n",
    "print(\"The shape of the dataset is:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the data types and non-null values for each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all columns are numerical (`dtype = float64`). However, check the column headers (and information about the dataset from the links given at the beginning of the notebook), and notice that you are actually dealing with multimodal data. The dataset has a mix of categorical, numerical, and potentially even text information.\n",
    "\n",
    "Cast the features accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"COW\",\n",
    "    \"SCHL\",\n",
    "    \"MAR\",\n",
    "    \"OCCP\",\n",
    "    \"POBP\",\n",
    "    \"RELP\",\n",
    "    \"SEX\",\n",
    "    \"RAC1P\",\n",
    "    \"GCL\",\n",
    "    \"SCH\",\n",
    "]\n",
    "\n",
    "numerical_features = [\"AGEP\", \"WKHP\", \"PWGTP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also notice the unintuitive feature names. With a few exceptions, it is difficult to understand what the features refer to. For example, MAR could refer to March, but in this dataset it encodes marital status. It could be worthwhile to rename the features so that it will be easier to understand what they refer to. You can do this by creating a renaming dictionary and using the Pandas `.rename()` method.\n",
    "\n",
    "Example of feature renaming:\n",
    "```\n",
    "# Create dictionary for new column names\n",
    "rename_dict = {\"COW\":\"worker_class\", \"SCHL\":\"educational_attainment\"} \n",
    "\n",
    "# Apply new names to DataFrame\n",
    "df.rename(rename_dict, axis=1, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast categorical features to `category`\n",
    "df[categorical_features] = df[categorical_features].astype(\"object\")\n",
    "\n",
    "# Cast numerical features to `int`\n",
    "df[numerical_features] = df[numerical_features].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the changes took effect, use `.info()` to check. Compare the results to the `df.info()` output above to make sure the features were cast correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can separate model features from the model target to explore them separately. \n",
    "\n",
    "### Model target and model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the target column you want to make predictions for\n",
    "model_target = \">50k\"\n",
    "# Combine the categorical and numerical features\n",
    "model_features = categorical_features + numerical_features\n",
    "\n",
    "print(\"Model features: \", model_features)\n",
    "print(\"Model target: \", model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the target is not accidentally part of the features\n",
    "model_target in model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good. You made sure that the target is not in the feature list. If the output of the previous cell is `True`, you need to remove the target by calling `model_features.remove(model_target)`.\n",
    "\n",
    "Next, you want to start creating some visualizations of the data that you are working with.\n",
    "\n",
    "Before starting with the plots, look at how many unique instances you have per column. This helps you avoid plotting charts with hundreds of unique values. To do this, filter for columns with fewer than 10 unique categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlist_fts = (\n",
    "    df[model_features]\n",
    "    .apply(lambda col: col.nunique())\n",
    "    .where(df[model_features].apply(lambda col: col.nunique()) < 10)\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "print(shortlist_fts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bar plots and histograms\n",
    "\n",
    "In this section, you examine the data with plots. \n",
    "\n",
    "__Important:__ These plots ignore null (missing) values. As you saw in the previous section, only one column in the dataset contains NA values: GCL (grandparents living with grandchildren).\n",
    "\n",
    "For plotting, you need to distinguish between plots for categorical data (bar plots) and plots for numerical data (histograms and scatterplots):\n",
    "\n",
    "* __Bar plots:__ These plots show counts of categorical data fields. The `value_counts()` function yields the counts of each unique value. To turn the value count into a plot, add `.plot.bar()`.\n",
    "\n",
    "* __Histograms:__ Histograms show distributions of numeric data. Data is divided into buckets or bins. Use histograms for numerical data to group data points together into buckets. The command to create a histogram is `df[feature_name].plot.hist(bins=5)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bar plots\n",
    "The features that are eligible for bar plots are all categorical features, including the target (which is also a binary categorical value). First, look at the distribution of the model target.\n",
    "\n",
    "#### Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot of showing the number of counts that \n",
    "# are 1 or 0 based on the >50k model_target\n",
    "df[model_target].value_counts().plot.bar(color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that you eventually want to build a model that can consider different groups. The sensitive attribute for this example will be the RAC1P feature.\n",
    "\n",
    "Now plot a similar chart, but include another dimension (the outcome). To do this, you need to group by the feature that you want to encode. You also want to stack the bar chart to be able to compare it to the bar chart from the previous cell. To do this, you will set the `alpha` transparency value below 1 to better see the horizontal grid lines of the plot background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color map for the different categories\n",
    "cmap = sns.set_palette(\"husl\", 9)\n",
    "\n",
    "# Perform grouping based on target and feature\n",
    "df.groupby([model_target, \"RAC1P\"])[\"RAC1P\"].count().unstack().plot(\n",
    "    kind=\"bar\", stacked=True, alpha=0.8\n",
    ")\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc=(1.04, 0), title=\"RAC1P\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature distribution\n",
    "\n",
    "Now you can start to explore other features (so far, you only looked at the distribution of the target). The first feature that you might want to explore could be the sensitive attribute itself. It can be helpful to know how many groups are in a sensitive feature column and how many instances there are per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RAC1P\"].value_counts().plot.bar(color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the same chart, but include another dimension. For this, you want to use another library, Seaborn. Seaborn has a method called `countplot()` that allows you to pass a DataFrame and feature columns as well as an additional column to use for color encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RAC1P on the x-axis and get counts; in addition, color is based on model target category\n",
    "sns.countplot(x=\"RAC1P\", hue=model_target, data=df, palette=\"husl\", dodge=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert these bar charts to percentage numbers to compare the groups more directly. Ultimately, you want to dive deeper into the groups with the biggest differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by RAC1P feature and count\n",
    "perc_df = pd.DataFrame(df.groupby(\"RAC1P\")[model_target].value_counts()).rename(\n",
    "    {model_target: \"count\"}, axis=1\n",
    ")\n",
    "\n",
    "# Calculate percentage total\n",
    "perc_df[\"count\"] / perc_df.groupby(\"RAC1P\")[\"count\"].transform(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Sum of individuals in group 6:\",perc_df[\"count\"][6].sum())\n",
    "print(\"Sum of individuals in group 8:\",perc_df[\"count\"][8].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the outcome is not equally distributed across all RAC1P categories. The biggest discrepancy appears to be category 8. This group has almost four times as many instances of income $\\leq$ 50k as above 50k. Group 8 has 22,793 individuals. If you compare this to group 6 (with 32,709 individuals), you should notice that the distribution of outcomes is different there, with an almost 50/50 split for the income levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">If you wanted to create a countplot for another feature, what would be the correct code snippet?</p>\n",
    "    <p style=\" text-align: center; margin: auto;\">(Ideally, you want to use a feature that you don't expect to be a contributing factor to the outcome, such as grandparents living with grandchildren.)</p>\n",
    "    <br>\n",
    "    <p style=\" text-align: center; margin: auto;\">To answer the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "question_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create another type of bar plot by using `.catplot()`. With this method, you can specify three dimensions of encoding at the same time. You can specify the feature that you want _counts_ for (for example, count of how many instances there are for each job category), generate comparison columns by using a second feature, and encode the outcome as color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"COW\", col=\"SEX\", kind=\"count\", hue=model_target, data=df, palette=\"husl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been divided by SEX into two charts. Each chart shows the number of people who make greater than 50k compaired to those who make less than 50k for each work class. You can observe a pay difference by sex and also by work class (job family)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "Histograms show distributions of numeric data. Data is divided into buckets or bins. Use histograms for numerical data to group data points together into buckets. The command to create a histogram is `df[<feature_name>].plot.hist(bins=n)`. Use this command in the following cell to create a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 bins to analyze the age feature\n",
    "df[\"AGEP\"].plot.hist(bins=10, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have expected a lognormal or normal distribution (with peak at around 45 years), but you actually see something that looks like a bimodal distribution with a cutoff at about 16 years. The cutoff occurs because the `adult_filter` was applied when the dataset was loaded. This was done to mimic the [UCI adult dataset](https://archive-beta.ics.uci.edu/dataset/20/census+income).\n",
    "\n",
    "The double peak could indicate that the dataset has two different subpopulations. Again, you might want to overlay another feature to check this. \n",
    "\n",
    "Because you are working with numerical data now, you need to use `.displot()` to create the overlay. You can specify a lot of things, such as whether you want percentages, absolute counts, or stacked bars or bars displayed next to one another. For more information, see [seaborn.displot](https://seaborn.pydata.org/generated/seaborn.displot.html) in the Seaborn documentation.\n",
    "\n",
    "This plotting method provides access to different types of histogram plots: \n",
    "- **hist:** Histogram; instance counts per bin\n",
    "- **kde:** Kernel density estimation\n",
    "- **ecdf:** Empirical cumulative distributions\n",
    "\n",
    "For more information about the methods, see [Visualizing Distributions of Data](https://seaborn.pydata.org/tutorial/distributions.html) in the Seaborn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    df,\n",
    "    x=\"AGEP\",\n",
    "    hue=\"SEX\",\n",
    "    aspect=1.2,\n",
    "    kind=\"hist\",\n",
    "    stat=\"count\",\n",
    "    bins=10,\n",
    "    multiple=\"stack\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization is not entirely conclusive. You can observe similar patterns for both types of sex that are recorded in the data. This raises the question of whether a combination of attributes lead to the bimodal peaks.\n",
    "\n",
    "You can also bin the age feature and split the plot by the model target. You would expect the younger age groups to have lower salaries because they are more likely to still be in school or working lower-salary jobs. To plot this, you can include a `col` parameter in `displot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    df,\n",
    "    x=\"AGEP\",\n",
    "    col=model_target,\n",
    "    bins=10,\n",
    "    palette=sns.color_palette(\"husl\", 2),\n",
    "    hue=model_target,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots are interesting because they suggest that different outcome classes have different underlying age distributions.\n",
    "\n",
    "You can look at this again by using the kernel density estimate option for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    df,\n",
    "    x=\"AGEP\",\n",
    "    hue=model_target,\n",
    "    aspect=1.2,\n",
    "    kind=\"kde\",\n",
    "    palette=sns.color_palette(\"husl\", 2),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Scatterplots\n",
    "\n",
    "Scatterplots are simple 2D plots of two numerical variables. You can use scatterplots to examine the relationship between two numerical variables. If both variables are moving up, it is a positive correlation. If one variable moves down and the other moves up, it is a negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    x=\"AGEP\",\n",
    "    y=\"WKHP\",\n",
    "    data=df.sample(\n",
    "        5000, random_state=1\n",
    "    ),  # Take a sample of data for quicker plotting\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that a relationship doesn't really exist. Try overlaying the outcome with a sensitive attribute by specifying a `hue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df.sample(\n",
    "        5000, random_state=1\n",
    "    ),  # Take a sample of data for quicker plotting\n",
    "    x=\"AGEP\",\n",
    "    y=\"WKHP\",\n",
    "    hue=\"SEX\",\n",
    "    palette=sns.color_palette(\"husl\", 2),\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "# Add legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start to see a pattern for the different SEX attributes, with class 1 appearing in the top half of the chart. The original goal was to look at the data split by RAC1P, and you can now see a second pattern emerging for another attribute (SEX).\n",
    "\n",
    "You can generally expect these effects to intersect, which leads to amplified adverse effects for subpopulations with multiple sensitive attributes. Ultimately, you want to build ML models that work for all subgroups. This plot highlights why it is important to check whether data has multiple sensitive attributes that are related to the outcome. In this particular case, you expect a correlation between hours worked and income, so you will quantify this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Correlation matrices\n",
    "\n",
    "Similar to scatterplots, a correlation matrix aims to pinpoint relationships between numerical features. Correlation values of -1 means perfect negative correlation, 1 means perfect positive correlation, and 0 means that no relationship exists between the two numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the font size to be larger and the size of the plot to be bigger\n",
    "sns.set(font_scale=1.2)\n",
    "plt.figure(figsize = (7,7))\n",
    "\n",
    "# Create the heatmap and plot it\n",
    "heatmap = sns.heatmap(df.corr(numeric_only=True), vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title(\"Correlation Matrix\", fontdict={\"fontsize\": 12}, pad=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, you see a positive correlation between age and salary as well as between hours worked and salary. However, does this also hold true if you split by the sensitive feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))\n",
    "fig.suptitle(\"Correlation Matrix by RAC1P Class\")\n",
    "plt.tight_layout(h_pad=4, w_pad=2)\n",
    "\n",
    "tickers = sorted(df[\"RAC1P\"].unique())\n",
    "for i, ax in zip(tickers, axs.ravel()):\n",
    "    sns.heatmap(\n",
    "        df[df[\"RAC1P\"] == i].drop([\"GCL\",\"RAC1P\"], axis=1).corr(numeric_only=True),\n",
    "        ax=ax,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        annot=True,\n",
    "    )\n",
    "    ax.set_title(\"Group Nr. %s\" % str(int(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, age is less correlated with the outcome for certain groups. This could indicate that being a member of a particular group has a bigger influence on the outcome than the age feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DPL and CI\n",
    "In this section, you will look at some specific measures that can help identify bias in a dataset.\n",
    "\n",
    "### DPL\n",
    "\n",
    "The difference in proportion of labels (DPL) compares the proportion of observed outcomes with positive labels for different groups in a dataset. For more information, see [Difference in Proportions of Labels (DPL)](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-data-bias-metric-true-label-imbalance.html) in the *Amazon SageMaker Developer Guide*.\n",
    "\n",
    "$ \\Large DPL = \\frac{n_{>50k \\wedge RAC1P=6}}{n_{RAC1P=6}} - \\frac{n_{>50k \\wedge RAC1P=8}}{n_{RAC1P=8}} $\n",
    "\n",
    "To calculate DPL, select two groups that you want to compare. From the analysis at the beginning of this lab, you know that for the feature RAC1P, groups 6 and 8 have the biggest relative difference in outcome, so you want to use those groups for further analysis.\n",
    "\n",
    "You can calculate DPL for more than two groups by selecting one reference group and then comparing against that particular group. You can also use multiple attributes to establish group membership (such as RAC1P and SEX).\n",
    "\n",
    "You can slice the DataFrame by using logical conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_50k_gr6 = len(df[(df[\">50k\"] == 1) & (df[\"RAC1P\"] == 6)])\n",
    "n_gr6 = len(df[df[\"RAC1P\"] == 6])\n",
    "\n",
    "n_50k_gr8 = len(df[(df[\">50k\"] == 1) & (df[\"RAC1P\"] == 8)])\n",
    "n_gr8 = len(df[df[\"RAC1P\"] == 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now calculate DPL. For binary and multicategory outcomes, the DPL values range over the interval (-1, 1):\n",
    "\n",
    "- Positive DPL values indicate that having attribute $a$ (for example, group membership \"6\") has a higher proportion of positive outcomes when compared with not having attribute $a$ (for example, group membership \"8\").\n",
    "\n",
    "- Values of DPL near zero indicate a more equal proportion of positive outcomes between groups with different attributes.\n",
    "\n",
    "- Negative DPL values indicate that not having attribute $a$ has a higher proportion of positive outcomes when compared with having attribute $a$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpl = n_50k_gr6 / n_gr6 - n_50k_gr8 / n_gr8\n",
    "dpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DPL is 0.28. This means that members of group 6 have a higher proportion of positive outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">Try to calculate the DPL between group 1 and group 8 in the cell below.\n",
    "    <br>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate DPL for group 1 and group 8\n",
    "############### CODE HERE ###############\n",
    "\n",
    "n_50k_gr1 = len(df[(df[\">50k\"] == 1) & (df[\"RAC1P\"] == 1)]) \n",
    "n_gr1 = len(df[df[\"RAC1P\"] == 1])\n",
    "n_50k_gr8 = len(df[(df[\">50k\"] == 1) & (df[\"RAC1P\"] == 8)])\n",
    "n_gr8 = len(df[df[\"RAC1P\"] == 8])\n",
    "n_50k_gr1 / n_gr1 - n_50k_gr8 / n_gr8\n",
    "\n",
    "############## END OF CODE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting value should be approximately 0.25. This means that group 1 has a higher proportion of positive outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CI (normalized)\n",
    "\n",
    "Class imbalance (CI) occurs when different group sizes are present in a dataset (groups based on a sensitive attribute or attributes). Here, you don't consider labels (outcomes), and you focus on the group sizes.\n",
    "\n",
    "$\\Large CI_{norm} = \\frac{n_{RAC1P=6}-n_{RAC1P=8}} {n_{RAC1P=6}+n_{RAC1P=8}}$\n",
    "\n",
    "CI values range from -1 to +1:\n",
    "- Positive CI values indicate that the group with attribute $a$ contains more examples than the other group.\n",
    "- CI values near 0 indicate that the groups are similar sizes.\n",
    "- Negative CI values indicate that the group with attribute $a$ contains fewer examples than the other group.\n",
    "\n",
    "Again, you can use DataFrame slicing to calculate the values. In fact, you can use `n_gr6` and `n_gr8` from the DPL calculation because these are the counts that you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_norm = (n_gr6 - n_gr8) / (n_gr6 + n_gr8)\n",
    "ci_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "In terms of group size imbalance, you can see from the CI metric that this dataset has more examples from group 6 than 8. This will be important to remember for next steps and also for model selection. You will need to specify that the model target is imbalanced and also that the groups that you want to consider are different sizes.\n",
    "\n",
    "Remember that models generally improve as you provide more data. The same is true for group-specific performance. You are dealing with target imbalance and group imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To finish this lab, continue to notebook 2.**"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
